---
title: "Addressing Subposterior Conflict With Weighted Proposals"
author: "Andrew Manderson"
date: "`r format(Sys.time(), '%d %B, %Y')`"
fontfamily: tgpagella
fontsize: 10pt
papersize: a4
geometry: margin=2.25cm
bibliography: ../0bibliography/year-1-bib.bib
csl: aam71-test.csl
output: 
  pdf_document:
    includes:
      in_header:
        tex-input/pre.tex
    fig_caption: true
    number_sections: true
    keep_tex: true
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, comment = NA, out.width = "100%", fig.align = "center", auto_pdf = TRUE, cache = TRUE, fig.width = 5, fig.asp = 0.5)
sim_pars <- readRDS("rds/norm-norm-ex/sim-pars.rds")
attach(sim_pars) # Needed to dynamically generate table
```

The need for accurate self-density ratio estimates arose from a conflict between $(m - 1)^{\text{th}}$ stage posterior and the unknown $m^{\text{th}}$ model's prior marginal distribution. 
This was purely a disagreement of scale, the distributions in question did not have disjoint supports.
This document considers subposteriors with disjoint supports, and demonstrates some potential solutions.

# Disjoint subposteriors

Consider the two subposteriors $\pd_{1}(\phi \mid Y_{1})$, $\pd_{2}(\phi \mid Y_{2})$, and melded posterior $\pmeld(\phi \mid Y_{1}, Y_{2})$ shown in Figure&nbsp;\ref{fig:subpost_disagreement}.
Using the samples of either of the subposteriors as a proposal for the overall posterior results in a degenerate sample of the overall posterior, due to an insufficient number of samples in the support of $\pmeld(\phi \mid, Y_{1}, Y_{2})$.
If instead we sample a version of one of the subposteriors which is _augmented_ by a function $\tarw_{1}(\phi; \eta_{1})$, i.e.&nbsp;$\pd_{1}(\phi \mid Y_{1})\tarw_{1}(\phi; \eta_{1})$, we can control the stage two acceptance probability through $\tarw_{1}(\phi; \eta_{1})$.
The green line in Figure&nbsp;\ref{fig:subpost_disagreement} illustrates how we can suitably scale and shift the stage one target. 

```{r subpost_disagreement, fig.cap = "Hypothetical conflicting subposteriors (blue), melded posterior (red), and the augmented stage one one target (green, dashed)."}
knitr::include_graphics("plots/intro/subpost-disagreement.pdf")
```

The general problem concerns instances where the support of $\pd_{\text{meld}, \modelindex - 1}(\phi, \psi_{1}, \ldots, \psi_{\modelindex - 1} \mid Y_{1}, \ldots, Y_{\modelindex - 1})$ does not intersect with the support of $\pd_{\text{meld}, \modelindex}(\phi, \psi_{1}, \ldots, \psi_{\modelindex} \mid Y_{1}, \ldots, Y_{\modelindex})$, hence also does not overlap with $\pd_{\modelindex}(\phi,~\psi_{\modelindex}~\mid~Y_{\modelindex})$.
We must choose the functional form of $\tarw_{\modelindex - 1}(\phi; \eta_{\modelindex - 1})$, as well as the parameter $\eta_{\modelindex - 1}$, such that the supports of $\pd_{\text{meld}, \modelindex - 1}(\phi, \psi_{1}, \ldots, \psi_{\modelindex - 1} \mid Y_{1}, \ldots, Y_{\modelindex - 1})\tarw_{\modelindex - 1}(\phi; \eta_{\modelindex - 1})$ and $\pd_{\text{meld}, \modelindex}(\phi, \psi_{1}, \ldots, \psi_{\modelindex} \mid Y_{1}, \ldots, Y_{\modelindex})$ intersect.

# Methods - Maths

Consider the overall melded target posterior for $\Nm = 2$ models
\input{tex-input/method/0010-melded-target-posterior.tex}
The _augmented stage one target_ is then
\input{tex-input/method/0020-stage-one-target.tex}
Hence, the stage two acceptance probability is 
\input{tex-input/method/0030-stage-two-acceptance.tex}

The presence of the $\tarw_{1}(\phi; \eta_{1})$ terms in the stage 2 acceptance probability implies that we have some degree of control over the acceptance rate.
The $\pd_{2}(\phi) \tarw_{1}(\phi; \eta_{1})$ term also suggests that this idea may be more linked than we suspect to our weighted estimation methodology for the prior marginal distribution.

For $\Nm > 2$, we will accrue an additional $\tarw_{\modelindex - 1}(\phi; \eta_{\modelindex - 1})$ term for each additional model, which may be problematic.

## Choosing $\tarw_{\modelindex}(\phi; \eta_{\modelindex})$

### Using summary statistics, assuming distribution is Normal

<!-- - An alternative may be to chose the parameters of the $\tarw_{\modelindex - 1}(\phi)$ using samples from $\pd_{\text{meld}, \modelindex - 1}(\phi \mid Y_{1})$ and $\pd_{\modelindex}(\phi \mid Y_{1})$.
    - This has an additional cost, as we have to resample the augmented version of $\pd_{\text{meld}, \modelindex - 1}$, in addition to separately sampling $\pd_{\modelindex}(\phi \mid Y_{1})$. -->

Say we use the samples of $\phi$ from $\pd_{\text{meld}, \modelindex - 1}(\phi, \psi_{1}, \ldots, \psi_{\modelindex - 1} \mid Y_{1}, \ldots, Y_{\modelindex - 1})$ as a proposal for $\pd_{\text{meld}, \modelindex}(\phi, \psi_{1}, \ldots, \psi_{\modelindex} \mid Y_{1}, \ldots, Y_{\modelindex})$ and observe the behaviour in Figure&nbsp;\ref{fig:no_u_traces}.
We can still use these samples, in combination with samples from $\pd_{\modelindex}(\phi, \psi_{\modelindex} \mid Y_{\modelindex})$, to choose an appropriate $\tarw_{\modelindex - 1}(\phi; \eta_{\modelindex - 1})$.

Define: 

- $\{\tilde{\phi}_{\sampleindex, \modelindex - 1}\}_{\sampleindex = 1, \ldots, \Nx}$ is a sample of size $\Nx$ from $\pd_{\text{meld}, \modelindex - 1}(\phi, \psi_{1}, \ldots, \psi_{\modelindex - 1} \mid Y_{1}, \ldots, Y_{\modelindex - 1})$.
    
    - I am using the tilde to differentiate between samples from the intermediary targets and samples from individual subposteriors.

- $\tilde{\mu}_{\modelindex - 1} = \frac{1}{\Nx}\sum\limits_{i = 1}^{\Nx}\tilde{\phi}_{\sampleindex, \modelindex - 1}$, the empirical mean of the $(\modelindex - 1)^{\text{th}}$ stage melded posterior.
- $\tilde{\sigma}^{2}_{\modelindex - 1} = \frac{1}{\Nx - 1}\sum\limits_{i = 1}^{\Nx} (\tilde{\phi}_{\sampleindex, \modelindex - 1} - \tilde{\mu}_{\modelindex - 1})^{2}$,  the empirical variance of the $(\modelindex - 1)^{\text{th}}$ stage melded posterior.

Likewise,

- $\{\phi_{\sampleindex, \modelindex}\}_{\sampleindex = 1, \ldots, \Nx}$ is a sample of size $\Nx$ from $\pd_{\modelindex}(\phi, \psi_{\modelindex} \mid Y_{\modelindex})$.
- $\mu_{\modelindex} = \frac{1}{\Nx}\sum\limits_{i = 1}^{\Nx}\phi_{\sampleindex, \modelindex}$, the empirical mean of the $\modelindex^{\text{th}}$ subposterior.
- $\sigma^{2}_{\modelindex} = \frac{1}{\Nx - 1}\sum\limits_{i = 1}^{\Nx} (\phi_{\sampleindex, \modelindex} - \mu_{\modelindex})^{2}$,  the empirical variance of the $\modelindex^{\text{th}}$ subposterior.

Next,

- $k = 1.05$, some safety factor.
    
    - We need some safety factor to ensure the target is integrable.
    - The integrability of the resulting target is a complicated function of the posterior and the space of possible $\tarw_{\modelindex - 1}(\phi; \eta_{\modelindex - 1})$ functions.
    - The tail behaviour is going to be important again.
        - Seems to be a recurrent theme. 

- $\mu_{\text{de}} = \tilde{\mu}_{\modelindex - 1}$
- $\sigma^{2}_{\text{de}} = k \tilde{\sigma}^{2}_{\modelindex - 1}$
- $\mu_{\text{nu}} = \frac{\tilde{\sigma}^{2}_{\modelindex - 1} \mu_{\modelindex} + \sigma^{2}_{\modelindex}\tilde{\mu}_{\modelindex - 1}} {\tilde{\sigma}^{2}_{\modelindex - 1} + \sigma^{2}_{\modelindex}}$
- $\sigma^{2}_{\text{nu}} = \frac{\tilde{\sigma}^{2}_{\modelindex - 1} \sigma^{2}_{\modelindex}}{\tilde{\sigma}^{2}_{\modelindex - 1} + \sigma^{2}_{\modelindex}}$

Denoting $f(\phi; \mu, \sigma^2)$ as the normal density function with mean $\mu$ and variance $\sigma^2$, we can now define 

- $\tarw_{\modelindex - 1}(\phi; \eta_{\modelindex - 1}) = \frac{f(\phi; \mu_{\text{nu}}, \sigma^2_{\text{nu}})} {f(\phi; \mu_{\text{de}}, \sigma^2_{\text{de}})}$.
- Implies $\eta_{\modelindex - 1} = \{\mu_{\text{nu}}, \sigma^{2}_{\text{nu}}, \mu_{\text{de}}, \sigma^{2}_{\text{de}}\}$

## Similarities to the _cavity distribution_ of @vehtari:etal:14

Our definition of $\tarw_{\modelindex - 1}(\phi; \eta_{\modelindex - 1})$ is very similar to the _cavity distribution_ of @vehtari:etal:14.
This suggests one may be able to address conflict between subposteriors in a similar way. 
Each submodel has its own $\tarw_{\modelindex}(\phi; \eta_{\modelindex})$ that is initially proportional to a constant.
After a certain number of parallel MCMC samples of the resulting target distributions, each $\tarw_{\modelindex}(\phi; \eta_{\modelindex})$ is updated using the information from the samples of all the target distributions.

## Potential issues

- Feasible in 1/2/(3?) dimensions, and melding cases where $\Nm$ is $<10$?. 
    - Trying to think of cases where it is easyish to figure out where the overall posterior will be by visual inspection.
    - More general idea for finding "midpoint" between samples from two distributions.
        - Seems a lot like the idea of Barycentres in: [@srivastava:etal:15; @srivastava:li:dunson:18].
        - Infact, I think this is identical in the 1-D case.
        - In the 2-or-more-D case, we have to start thinking about covariance as well. 
- Can use ESS as a diagnostic for particle degeneracy?
 
# Example - normal normal

Starting from the same normal-normal model used to demonstrate the importance of accurately estimating the prior marginal distribution, we adjust some of the hyperparmeters to manufacture disjoint subposteriors.
There are $\Nm = 2$ models, with common parameter $\phi$,
\input{tex-input/norm-norm-ex/0010-norm-models.tex}
We simulate `r n_y_1` observations from model 1, i.e.&nbsp;$Y_{1}$ is a vector of length `r n_y_1`, and `r n_y_2` observations from model 2.
The observations variances $\varepsilon_{1}^{2}$ and $\varepsilon_{2}^{2}$ are fixed to
`r sigma_1` and `r sigma_2` respectively.
The prior means $\mu_{1}$ and $\mu_{2}$ are `r mu_phi_1` and `r mu_phi_2`, whilst the prior variances are `r sigma_phi_1` and `r sigma_phi_2`.
This configuration results in the subposterior distributions in Figure&nbsp;\ref{fig:subposteriors}.

```{r subposteriors, fig.cap = "Disjoint subposteriors for the normal normal example."}
knitr::include_graphics("plots/norm-norm-ex/subposteriors.pdf")
```

The pooled prior is formed by linear pooling. 
For the mulit-stage samplers, the stage one target is defined in Equation&nbsp;\eqref{eqn:stage-one-target}.

## Stage one target and $\text{u}_{1}(\phi)$.

Here we choose $\text{u}_{1}(\phi)$ via the method described in Section&nbsp;\ref{choosing-tarw_modelindexphi-eta_modelindex}. 
Figure&nbsp;\ref{fig:u_func_augmented_target} displays $\text{u}_{1}(\phi)$ (right panel) and the augmented target $\tilde{\pd}_{\text{meld}, 1}(\phi, \psi_{1}, Y_{1})$ (left panel).
The augmented target now lies inbetween the two subposteriors depicted in Figure&nbsp;\ref{fig:subposteriors}.

```{r u_func_augmented_target, fig.cap ="The augmented stage one target (left panel) and corresponding $\\text{u}_{1}(\\phi)$ (right panel)."}
knitr::include_graphics("plots/norm-norm-ex/u-function-augmented-target.pdf")
```

## Numerical tests

We want to compare the melded posterior distribution sampled using the following methods:

- Multi-stage sampler, no augmentation function (normal melding).
- Multi-stage sampler, _with_ augmentation function.
- Directly sampling the melded posterior, as a point of reference.

We can analytically compute the melded posterior, however evaluating is numerically challenging.
I have yet to find the calculations that introduce the numerical inaccuracy I observe. 

#### Sequential MH, with no $\text{u}_{1}(\phi)$ (normal melding)

Here we apply the multi-stage sampler with no augmentation function, or equivalently set $\tarw_{1}(\phi; \eta_{1}) = 1$.
The traceplots in Figure&nbsp;\ref{fig:no_u_traces} demonstrate the issue with this approach, specifically that the support of the first stage does not intersect with the support of the melded posterior.

```{r no_u_traces, fig.cap = "Traceplots for the first and second stage target distributions, with no subposterior augmentation."}
knitr::include_graphics("plots/norm-norm-ex/no-u/stage-traces.pdf")
```

#### Sequential MH, _with_ $\text{u}_{1}(\phi)$ (idea developed here)

Now we sample the augmented target in the first stage, for use in the second and final stage.
Figure&nbsp;\ref{fig:with_u_traces_2} shows a clear improvement in performance over Figure&nbsp;\ref{fig:no_u_traces}. 

```{r with_u_traces_2, fig.cap = "Traceplots for the fist and second stage targets distributions, \\textit{with} augmented stage one target."}
knitr::include_graphics("plots/norm-norm-ex/with-u-2/stage-traces.pdf")
```

####  Joint MH - sampling $\pmeld(\phi \mid Y_{1}, Y_{2})$ directly 

In this example we can specify the melded posterior in Stan directly.
Figure&nbsp;\ref{fig:joint_trace} is the traceplot of the sampler that directly targets the melded posterior.

```{r joint_trace, fig.cap = "Traceplot of the directly sampled melded posterior."}
knitr::include_graphics("plots/norm-norm-ex/joint/trace.pdf")
```

We compare the sample quantiles of the melded joint posterior and the stage two melded posterior obtained using the augmented stage one target in Figure&nbsp;\ref{fig:joint_augmented_compare}, and we see good agreement between the two samples.

```{r joint_augmented_compare, fig.cap = "Quantile-quantile plot of sample quantiles obtained by directly sampling the melded joint posterior (x-axis) and the stage two sample quantiles obtained using the augmented stage one target (y-axis)."}
knitr::include_graphics("plots/norm-norm-ex/joint-augmented-compare.pdf")
```

# Computational costs

## Multi-stage Metropolis-Hastings within Gibbs

### Two submodel case {-}


We would like to generate $\Nx$ samples from the overall melded posterior, and hence opt to generate $\Nx$ samples from the stage one target.
Each stage one sample has a computational cost of order $\mathcal{O}(C_{1})$ which involves evaluating the unnormalised logposterior ($\mathcal{O}(C_{1, \text{lp}})$), and generating and evaluating a proposal for the link parameter ($\mathcal{O}(C_{1, \mathcal{Q}})$).
Note that $\mathcal{O}(C_{1}) = \mathcal{O}(C_{1, \text{lp}} + C_{1, \mathcal{Q}})$.
The analogous set of costs exist for the second stage target.

First we have to identify that we have a problem:

- The cost of sampling the original stage one target: $\mathcal{O}(\Nx C_{1})$.
- The cost of evaluating said samples in stage two: $\mathcal{O}(\Nx C_{2, \text{lp}})$.

Now we can solve it by:

- Sampling the second stage subposterior: $\mathcal{O}(\Nx C_{2})$.
    - This does not include the pooled prior.
- Sampling the augmented stage one target: $\mathcal{O}(\Nx C_{1}')$.
    - The prime indicates that the augmented target has strictly greater computational cost to evaluate.
- Evaluating the augmented samples in stage two: $\mathcal{O}(\Nx C_{2, \text{lp}})$.

### More than two submodels {-}

Fri 26 Jul 13:16:49 2019: _I don't think this is correct, consider three subposteriors in a triangle._

If we have $\Nm > 2$ models, then the costs grow in the following way.

Identifying the problem:

- We finish sampling the $\modelindex-1$th stage target: $\mathcal{O}(\Nx (C_{1}  + C_{2, \text{lp}} + \ldots + C_{\modelindex - 1, \text{lp}}))$.
- Then, we evaluate these samples under the $\modelindex$th stage: $\mathcal{O}(\Nx C_{\modelindex, \text{lp}})$ and realise we have conflict.

Addressing the issue:

- Sampling all the subposteriors: $\mathcal{O}(\Nx (C_{1} + \ldots + C_{\Nm}))$
- Sampling the augmented stage one target $\mathcal{O}(\Nx C_{1}')$.
- Evaluating them under the augmented intermediary targets: $\mathcal{O}(\Nx (C_{2, \text{lp}}' + \ldots + C_{\Nm, \text{lp}}))$.
    - Unless we augmented all the intermediary targets, any one stage could render the sample degenerate.
    - We do __not__ augment the final target.


## Sequential Monte Carlo (SMC) 

Adopting an SMC approach alleviates the need for initial runs to both diagnose conflict, and calculate an appropriate augmentation function $\tarw_{1}(\phi; \eta_{1})$.
Consider the $\Nm = 2$ models case initially.
If introducing each submodel requires $T$ tempering steps, each with a single refreshment step, and we wish to generate $\Nx$ samples, the computational costs include:

- Sampling the stage one target: $\mathcal{O}(\Nx C_{1})$.
- Evaluating the $T$ tempered likelihoods, and then refreshing the particles: $\mathcal{O}(\Nx T (C_{1} + C_{2}))$.
    <!-- - Tempered likelihood strictly has a different cost, and the MCMC refreshment step needs to target something slightly augmented. -->
- The overall cost is then $\mathcal{O}(\Nx T (2 C_{1} + C_{2}))$.

We can extrapolate this to $\Nm > 2$ models.
Assume introducing each additional submodel also requires $T$ tempering steps.
The final computational cost is then $\mathcal{O}(\Nx T (\Nm C_{1} + (\Nm - 1) C_{2} + \ldots + C_{\Nm}))$.
Perhaps there are ways to reduce the number of times we need to evaluate the previous models when introducing the $\modelindex$th model.
A careful reading of [@lindsten:etal:17] seems prudent, as the naive SMC algorithm I am envisaging here involves evaluating the joint model (i.e. all the data).


# Example - real world? Where can we get disjoint conflict from.

- Investigate the Carlin example Rob sent

<!-- -------------------- END OF MAIN BODY OF DOCUMENT -------------------- -->
\newpage

<!-- The {-} tag here suppresses the section numbering. -->
# Bibliography {-}

<!-- This makes pandoc-citeproc put the references before the end of document. -->
<div id="refs"></div>

\newpage

<!-- Now switch to alphabetical numbering for the appendix, and reset the counter. -->
\renewcommand{\thesection}{\Alph{section}}
\setcounter{section}{0}

# Appendix 